{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define path\n",
    "wesley_ds = \"/files\"\n",
    "kaggle_ds = \"/archive/Data/genres_original\"\n",
    "main_path = \"Dataset\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#choose the dataset\n",
    "chooser = wesley_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = main_path+chooser\n",
    "# DATASET_PATH = \"../../../Music\"\n",
    "JSON_PATH = 'complete_3_first.json'\n",
    "SAMPLE_RATE = sr =  22050\n",
    "DURATION = 30 #measured in seconds \n",
    "SAMPLES_PER_TRACK = SAMPLE_RATE*DURATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk(main_path+chooser):\n",
    "    for filename in filenames:\n",
    "        #print(os.path.join(dirname, filename))\n",
    "        print(filename)\n",
    "# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "# import soundfile as sf\n",
    "# import librosa\n",
    "# import librosa.display\n",
    "from IPython.display import Audio\n",
    "# from tqdm import tqdm \n",
    "from sklearn.model_selection import train_test_split, TimeSeriesSplit\n",
    "# import tensorflow as tf\n",
    "# from tensorflow import keras\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, LSTM, Bidirectional, GRU, BatchNormalization, LeakyReLU\n",
    "# from tensorflow.keras.utils import to_categorical\n",
    "# import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import os\n",
    "import math\n",
    "import json\n",
    "import random\n",
    "# import mutagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_mfcc(dataset_path, json_path, n_mfcc=13, n_fft=4084, hop_length=1024, num_segments=10):\n",
    "    #dictionary to store data\n",
    "    data = {\n",
    "        'mapping' : [],\n",
    "        'mfcc' : [],\n",
    "        'labels' : [],\n",
    "        'energy': [],\n",
    "        'key': []\n",
    "    }\n",
    "    \n",
    "    count = 0 # To keep track of our progress\n",
    "    num_samples_per_segment = int(SAMPLES_PER_TRACK / num_segments) \n",
    "    expected_num_mfcc_vectors_per_segment = math.ceil(num_samples_per_segment / hop_length)\n",
    "    \n",
    "    #Loop through all the genres\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        #ensure that we're not at the root level\n",
    "        if dirpath not in dataset_path:\n",
    "\n",
    "            #save the semantic label\n",
    "            dirpath_components = dirpath.split('/')\n",
    "            semantic_label = dirpath_components[-1]\n",
    "            data['mapping'].append(semantic_label)\n",
    "            print('\\nProcessing {}'.format(semantic_label))\n",
    "            \n",
    "            #process files for a specific genre \n",
    "            for f in filenames:\n",
    "#                 if f.endswith('.wav') and f != 'jazz.00054.wav': # Since file jazz.00054.wav is an empty file\n",
    "                if f.endswith('.mp3') or f.endswith('.MP3'): # Since file jazz.00054.wav is an empty file\n",
    "                    file_path = os.path.join(dirpath,f)\n",
    "                    \n",
    "                    #loading the audio file \n",
    "                    # we are using the soundfile library since it is faster than librosa\n",
    "                    signal, sr = librosa.load(file_path) # len(signal) = 661794  # sr is 22050 by default\n",
    "                    try:\n",
    "                        temp1 = str(mutagen.File(file_path)['TXXX:EnergyLevel'])\n",
    "                    \n",
    "                        temp2 = str(mutagen.File(file_path)['TKEY'])\n",
    "                    except:\n",
    "                        continue\n",
    "                    midptr = int(signal.shape[0]/2)\n",
    "                    bptr = midptr - (SAMPLE_RATE*int(DURATION/2)) #set as OFFSET\n",
    "#                     hptr = midptr + (SAMPLE_RATE*duration)\n",
    "                    #print(signal,sr)\n",
    "                    #process segments extracting mfcc and storing data\n",
    "                    for s in range(num_segments): \n",
    "                        # Since num_segments is defined as 5. Every 30 sec file is divided into 5 segments of length 6sec \n",
    "                        # Start sample would keep track of the index of the first element of each 6 second batch\n",
    "                        # finish sample would keep track of the index of the last element of each 6 second batch\n",
    "                        # And then with the help of python's slice functionality we will extract that 6 second batch from every 30 sec signal\n",
    "                        start_sample = bptr + num_samples_per_segment * s   \n",
    "                        finish_sample = num_samples_per_segment + start_sample\n",
    "                        \n",
    "                        # Next, we will pass each segment in order to extract MFCC. The parameter n_mfcc defines the number of mfcc \n",
    "                        # we need to extract, Usually n_mfcc is set b/w 13 to 40. The other parameters n_fft and hop length are \n",
    "                        # indivisual topics of discussion. Will be discussed in later Notbooks. \n",
    "                        mfcc = librosa.feature.mfcc(signal[start_sample : finish_sample],\n",
    "                                                   sr = sr,\n",
    "                                                   n_fft = n_fft,\n",
    "                                                   n_mfcc = n_mfcc,\n",
    "                                                   hop_length = hop_length)\n",
    "\n",
    "                        mfcc = mfcc.T\n",
    "                        # store mfcc for segment if it has the expected length\n",
    "                        if len(mfcc) == expected_num_mfcc_vectors_per_segment:\n",
    "                            print(mfcc.shape)\n",
    "                            data['mfcc'].append(mfcc.tolist())\n",
    "                            data['labels'].append(i)\n",
    "                            data['energy'].append(temp1)\n",
    "                            data['key'].append(temp2)\n",
    "                            print('Processing {}, segment:{}'.format(file_path, s))\n",
    "                            count += 1\n",
    "                            print(count)\n",
    "    with open(json_path, 'w') as fp:\n",
    "        json.dump(data, fp, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's run the above function \n",
    "save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the saved Json file\n",
    "def load_data(path):\n",
    "    with open(path, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        \n",
    "    #Convert lists into numpy arrays\n",
    "    inputs = data['mfcc']\n",
    "    targets = data['labels'] \n",
    "    return np.array(inputs), np.array(targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(targets, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for key purpose\n",
    "targets2 = np.array([outp_key.index(isi) for isi in targets])\n",
    "print(targets2)\n",
    "\n",
    "for isi in targets:\n",
    "    print(outp_key[outp_key.index(isi)], isi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.unique(targets2, return_counts=True))\n",
    "print(len(outp_key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "\n",
    "model.add(GRU(600, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "\n",
    "# model.add(GRU(100, return_sequences=True, input_shape=(inputs.shape[1], inputs.shape[2])))\n",
    "# model.add(GRU(200, return_sequences=True))\n",
    "# model.add(Dropout(0.2))\n",
    "# model.add(BatchNormalization())\n",
    "# model.add(GRU(500))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "# model.add(BatchNormalization())\n",
    "\n",
    "model.add(Dense(24, 'softmax'))\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(inputs_train, targets_train,\n",
    "          validation_data=(inputs_test, targets_test),\n",
    "          epochs = 35,\n",
    "          batch_size=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_ds(inputs, outputs):\n",
    "    inputs_cpy = np.array(inputs)\n",
    "    inputs_ori = np.array(inputs)\n",
    "    outputs_cpy = np.array(outputs)\n",
    "    # Adding Noise \n",
    "    \n",
    "    for i in range(inputs_cpy.shape[0]):\n",
    "        s = np.random.rand(inputs_cpy.shape[1], inputs_cpy.shape[2])\n",
    "        inputs_cpy[i] = inputs_cpy[i] + s\n",
    "\n",
    "    #join dataset\n",
    "    inputs_cpy = np.vstack((inputs_cpy, inputs_ori))\n",
    "    outputs_cpy = np.hstack((outputs, outputs))\n",
    "    print(inputs_cpy.shape, outputs_cpy.shape)\n",
    "    return inputs_cpy, outputs_cpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes, prob_do):\n",
    "        super(RNN, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.do = nn.Dropout(p=prob_do)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device) \n",
    "        out, _ = self.gru(x, h0)  \n",
    "        out = out[:, -1, :]\n",
    "        out = self.do(out)\n",
    "        out = torch.sigmoid(self.fc(out))\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_models(input_size, hidden_size, num_classes, device, prob_do = 0.5, num_layers = 1):\n",
    "    return RNN(input_size, hidden_size, num_layers, num_classes, prob_do).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def train_models(num_epoch, batch_size, learning_rate, inputs, outputs, splitts, device, folds = 0):\n",
    "    train_index, test_index = splitts[folds]\n",
    "    x_train = inputs[train_index]\n",
    "    y_train = outputs[train_index]\n",
    "    \n",
    "    x_train, y_train = augment_ds(x_train, y_train)\n",
    "    x_test = inputs[test_index]\n",
    "    y_test = outputs[test_index]\n",
    "    \n",
    "    models = create_models(inputs.shape[-1], 600, 5, device, prob_do = 0.4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(models.parameters(), lr=learning_rate)\n",
    "    \n",
    "    x_train = torch.from_numpy(x_train)\n",
    "    y_train = torch.from_numpy(y_train)\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "    y_test = torch.from_numpy(y_test)\n",
    "#     x_val = torch.from_numpy(x_val)\n",
    "#     y_val = torch.from_numpy(y_val)\n",
    "    \n",
    "    print(x_train.shape)\n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    acc_arr = []\n",
    "    train = TensorDataset(x_train, y_train)\n",
    "    test = TensorDataset(x_test, y_test)\n",
    "#     val = TensorDataset(x_val, y_val)\n",
    "    \n",
    "    train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "    test_loader = DataLoader(test, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "#     val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "#     test_loader_one = DataLoader(test, batch_size=1, shuffle=False, drop_last=True)\n",
    "    for epoch in range(num_epoch):\n",
    "        # training sequences\n",
    "        batch_losses = []\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch = x_batch.view([batch_size, -1, inputs.shape[-1]]).to(device).to(torch.float32)\n",
    "            y_batch = y_batch.to(device).to(torch.int64)\n",
    "            \n",
    "            models.train()\n",
    "            y_hat = models(x_batch)\n",
    "            loss = criterion(y_hat, y_batch)\n",
    "\n",
    "            # Backward and optimize\n",
    "            loss.backward()\n",
    "            # Updates parameters and zeroes gradients\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            batch_losses.append(loss.item())\n",
    "        train_loss.append(np.mean(batch_losses))\n",
    "        \n",
    "        #testing sequences\n",
    "        with torch.no_grad():\n",
    "            batch_val_losses = []\n",
    "            for x_val, y_val in test_loader:\n",
    "                x_val = x_val.view([batch_size, -1, inputs.shape[-1]]).to(device).to(torch.float32)\n",
    "                y_val = y_val.to(device).to(torch.int64)\n",
    "                models.eval()\n",
    "                yhat = models(x_val)\n",
    "                val_loss = criterion(yhat, y_val)\n",
    "                batch_val_losses.append(val_loss.item())\n",
    "            test_loss.append(np.mean(batch_val_losses))\n",
    "        \n",
    "        print(f\"[{epoch+1}/{num_epoch}] Training loss: {train_loss[-1]:.4f}\\t Validation loss: {test_loss[-1]:.4f}\", end=\"\\n\")\n",
    "            \n",
    "    return models,train_loss, test_loss, acc_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(models, test_loader,device, batch_size):\n",
    "    with torch.no_grad():\n",
    "        n_correct = 0\n",
    "        n_samples = 0\n",
    "        batch_acc = []\n",
    "        #labels = labels.to(device)\n",
    "        for x_test, y_test in test_loader:\n",
    "            x_test = x_test.view([batch_size, -1, x_test.shape[-1]]).to(device)\n",
    "            y_test = y_test.to(device)\n",
    "            x_test = x_test.to(torch.float32)\n",
    "            y_test = y_test.to(torch.int64)\n",
    "            models.eval()  \n",
    "            outputs = models(x_test)\n",
    "            # max returns (value ,index)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            n_samples += y_test.size(0)\n",
    "#             print(y_test)\n",
    "            n_correct += (predicted == y_test).sum().item()\n",
    "            acc = 100.0 * n_correct / n_samples\n",
    "            batch_acc.append(acc)\n",
    "#         print(n_correct)\n",
    "        print(f'Accuracy: {np.mean(batch_acc) :.4f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, targets = load_data(JSON_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6640,)\n"
     ]
    }
   ],
   "source": [
    "#device conf\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = 5 #deprecated\n",
    "num_epochs = 30\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "hidden_size = 500 #deprecated\n",
    "num_layers = 1 #deprecated\n",
    "\n",
    "from sklearn.model_selection import KFold as StratifiedKFold\n",
    "# manage dataset\n",
    "\n",
    "# split training and testing\n",
    "x_train, x_val, y_train, y_val = train_test_split(inputs, targets, test_size=0.1)\n",
    "x_val = torch.from_numpy(x_val)\n",
    "y_val = torch.from_numpy(y_val)\n",
    "val = TensorDataset(x_val, y_val)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10)\n",
    "output_lst = [\"BASS HOUSE\", \"BIG ROOM\", \"DEEP HOUSE\", \"ELECTRO HOUSE\", \"FUTURE HOUSE\"]\n",
    "outp_key = ['1A', '2A', '3A', '4A', '5A', '6A', '7A', '8A', '9A', '10A', '11A', '12A', '1B', '2B', '3B', '4B', '5B', '6B', '7B', '8B', '9B', '10B', '11B', '12B']\n",
    "\n",
    "#for genre purpose\n",
    "targets = np.array([isi-1 for isi in targets])\n",
    "print(targets.shape)\n",
    "row_skf = [content for content in skf.split(x_train, y_train)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6640, 65, 13)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10756, 65, 13) (10756,)\n",
      "torch.Size([10756, 65, 13])\n",
      "[1/30] Training loss: 1.3879\t Validation loss: 1.3356\n",
      "[2/30] Training loss: 1.2820\t Validation loss: 1.3031\n",
      "[3/30] Training loss: 1.2111\t Validation loss: 1.2640\n",
      "[4/30] Training loss: 1.1423\t Validation loss: 1.1975\n",
      "[5/30] Training loss: 1.0904\t Validation loss: 1.1760\n",
      "[6/30] Training loss: 1.0642\t Validation loss: 1.1949\n",
      "[7/30] Training loss: 1.0393\t Validation loss: 1.1658\n",
      "[8/30] Training loss: 1.0177\t Validation loss: 1.1606\n",
      "[9/30] Training loss: 1.0070\t Validation loss: 1.1533\n",
      "[10/30] Training loss: 1.0073\t Validation loss: 1.1728\n",
      "[11/30] Training loss: 1.0073\t Validation loss: 1.1765\n",
      "[12/30] Training loss: 0.9997\t Validation loss: 1.1493\n",
      "[13/30] Training loss: 0.9787\t Validation loss: 1.1321\n",
      "[14/30] Training loss: 0.9573\t Validation loss: 1.1244\n",
      "[15/30] Training loss: 0.9611\t Validation loss: 1.1217\n",
      "[16/30] Training loss: 0.9548\t Validation loss: 1.1260\n",
      "[17/30] Training loss: 0.9576\t Validation loss: 1.1352\n",
      "[18/30] Training loss: 0.9587\t Validation loss: 1.1191\n",
      "[19/30] Training loss: 0.9693\t Validation loss: 1.1671\n",
      "[20/30] Training loss: 0.9716\t Validation loss: 1.1136\n",
      "[21/30] Training loss: 0.9551\t Validation loss: 1.1167\n",
      "[22/30] Training loss: 0.9636\t Validation loss: 1.1289\n",
      "[23/30] Training loss: 0.9614\t Validation loss: 1.1234\n",
      "[24/30] Training loss: 0.9580\t Validation loss: 1.1259\n",
      "[25/30] Training loss: 0.9777\t Validation loss: 1.1599\n",
      "[26/30] Training loss: 0.9721\t Validation loss: 1.1084\n",
      "[27/30] Training loss: 0.9552\t Validation loss: 1.1352\n",
      "[28/30] Training loss: 0.9563\t Validation loss: 1.1186\n",
      "[29/30] Training loss: 0.9564\t Validation loss: 1.1556\n",
      "[30/30] Training loss: 0.9520\t Validation loss: 1.1156\n",
      "Accuracy: 81.3000 %\n"
     ]
    }
   ],
   "source": [
    "# for index in range(10):\n",
    "#     model, tl, tsl, acr = train_models(num_epochs, batch_size, learning_rate, x_train, y_train, row_skf, device, folds = index)\n",
    "#     evaluation(model, val_loader,device, batch_size)\n",
    "# # evaluation(model, ldr,device, batch_size)\n",
    "\n",
    "model, tl, tsl, acr = train_models(num_epochs, batch_size, learning_rate, x_train, y_train, row_skf, device, folds = 0)\n",
    "evaluation(model, val_loader,device, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "torch.save(model.state_dict(), '81_3_genre_inf.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\symbolic.py:173: UserWarning: ONNX export failed on RNN/GRU/LSTM because batch_first not supported\n",
      "  warnings.warn(\"ONNX export failed on \" + op + \" because \" + msg + \" not supported\")\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "ONNX export failed: Couldn't export operator aten::gru\n\nDefined at:\n<ipython-input-22-8e1b1a5a1eeb>(14): forward\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\nn\\modules\\module.py(481): _slow_forward\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\nn\\modules\\module.py(491): __call__\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\jit\\__init__.py(294): forward\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\nn\\modules\\module.py(493): __call__\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\jit\\__init__.py(231): get_trace_graph\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(225): _trace_and_get_graph_from_model\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(266): _model_to_graph\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(363): _export\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(131): export\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\__init__.py(25): export\n<ipython-input-40-84ad4c138d80>(16): <module>\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3343): run_code\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3263): run_ast_nodes\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3072): run_cell_async\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\async_helpers.py(68): _pseudo_sync_runner\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2895): _run_cell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2867): run_cell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\zmqshell.py(539): run_cell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\ipkernel.py(302): do_execute\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(234): wrapper\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelbase.py(538): execute_request\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(234): wrapper\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelbase.py(261): dispatch_shell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(234): wrapper\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelbase.py(358): process_one\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(775): run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(814): inner\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\ioloop.py(741): _run_callback\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\ioloop.py(688): <lambda>\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\asyncio\\events.py(145): _run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\asyncio\\base_events.py(1462): _run_once\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\asyncio\\base_events.py(442): run_forever\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelapp.py(612): start\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\traitlets\\config\\application.py(664): launch_instance\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel_launcher.py(16): <module>\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\runpy.py(85): _run_code\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\runpy.py(193): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%input : Float(1, 65, 13),\n      %gru.weight_ih_l0 : Float(1800, 13),\n      %gru.weight_hh_l0 : Float(1800, 600),\n      %gru.bias_ih_l0 : Float(1800),\n      %gru.bias_hh_l0 : Float(1800),\n      %fc.weight : Float(5, 600),\n      %fc.bias : Float(5)):\n  %7 : Long() = onnx::Constant[value={0}](), scope: RNN\n  %8 : Tensor = onnx::Shape(%input), scope: RNN\n  %9 : Long() = onnx::Gather[axis=0](%8, %7), scope: RNN\n  %10 : Long() = onnx::Constant[value={1}](), scope: RNN\n  %11 : Long() = onnx::Constant[value={600}](), scope: RNN\n  %12 : Tensor = onnx::Unsqueeze[axes=[0]](%10)\n  %13 : Tensor = onnx::Unsqueeze[axes=[0]](%9)\n  %14 : Tensor = onnx::Unsqueeze[axes=[0]](%11)\n  %15 : Tensor = onnx::Concat[axis=0](%12, %13, %14)\n  %16 : Float(1, 1, 600) = onnx::ConstantOfShape[value={0}](%15), scope: RNN\n  %17 : Float(1, 1, 600) = onnx::Cast[to=1](%16), scope: RNN\n  %18 : Long() = onnx::Constant[value={1}](), scope: RNN/GRU[gru]\n  %19 : Long() = onnx::Constant[value={1}](), scope: RNN/GRU[gru]\n  %20 : Double() = onnx::Constant[value={0}](), scope: RNN/GRU[gru]\n  %21 : Long() = onnx::Constant[value={0}](), scope: RNN/GRU[gru]\n  %22 : Long() = onnx::Constant[value={0}](), scope: RNN/GRU[gru]\n  %23 : Long() = onnx::Constant[value={1}](), scope: RNN/GRU[gru]\n  %24 : Float(1!, 65, 600), %25 : Float(1, 1, 600) = aten::gru(%input, %17, %gru.weight_ih_l0, %gru.weight_hh_l0, %gru.bias_ih_l0, %gru.bias_hh_l0, %18, %19, %20, %21, %22, %23), scope: RNN\n  %26 : Long() = onnx::Constant[value={-1}](), scope: RNN\n  %27 : Float(1, 600) = onnx::Gather[axis=1](%24, %26), scope: RNN/Dropout[do]\n  %28 : Float(1, 5) = onnx::Gemm[alpha=1, beta=1, transB=1](%27, %fc.weight, %fc.bias), scope: RNN/Dropout[do]\n  %output : Float(1, 5) = onnx::Sigmoid(%28), scope: RNN\n  return (%output)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-84ad4c138d80>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m                   \u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m  \u001b[1;31m# whether to execute constant folding for optimization\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m                   \u001b[0minput_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'input'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m   \u001b[1;31m# the model's input names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                   \u001b[0moutput_names\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'output'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# the model's output names\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m                  )\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\__init__.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0monnx\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexport\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36mexport\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, aten, export_raw_ir, operator_export_type, opset_version, _retain_param_name, do_constant_folding, strip_doc_string)\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[0moperator_export_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moperator_export_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mopset_version\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m             \u001b[0m_retain_param_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0m_retain_param_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdo_constant_folding\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m             strip_doc_string=strip_doc_string)\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py\u001b[0m in \u001b[0;36m_export\u001b[1;34m(model, args, f, export_params, verbose, training, input_names, output_names, operator_export_type, export_type, example_outputs, propagate, opset_version, _retain_param_name, do_constant_folding, strip_doc_string)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mexport_params\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m             proto, export_map = graph._export_onnx(params_dict, opset_version, defer_weight_export, operator_export_type,\n\u001b[1;32m--> 369\u001b[1;33m                                                    strip_doc_string)\n\u001b[0m\u001b[0;32m    370\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m             \u001b[0mproto\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexport_map\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_export_onnx\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopset_version\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moperator_export_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrip_doc_string\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: ONNX export failed: Couldn't export operator aten::gru\n\nDefined at:\n<ipython-input-22-8e1b1a5a1eeb>(14): forward\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\nn\\modules\\module.py(481): _slow_forward\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\nn\\modules\\module.py(491): __call__\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\jit\\__init__.py(294): forward\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\nn\\modules\\module.py(493): __call__\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\jit\\__init__.py(231): get_trace_graph\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(225): _trace_and_get_graph_from_model\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(266): _model_to_graph\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(363): _export\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\utils.py(131): export\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\torch\\onnx\\__init__.py(25): export\n<ipython-input-40-84ad4c138d80>(16): <module>\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3343): run_code\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3263): run_ast_nodes\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(3072): run_cell_async\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\async_helpers.py(68): _pseudo_sync_runner\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2895): _run_cell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\IPython\\core\\interactiveshell.py(2867): run_cell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\zmqshell.py(539): run_cell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\ipkernel.py(302): do_execute\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(234): wrapper\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelbase.py(538): execute_request\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(234): wrapper\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelbase.py(261): dispatch_shell\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(234): wrapper\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelbase.py(358): process_one\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(775): run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(162): _fake_ctx_run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\gen.py(814): inner\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\ioloop.py(741): _run_callback\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\ioloop.py(688): <lambda>\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\asyncio\\events.py(145): _run\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\asyncio\\base_events.py(1462): _run_once\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\asyncio\\base_events.py(442): run_forever\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\tornado\\platform\\asyncio.py(199): start\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel\\kernelapp.py(612): start\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\traitlets\\config\\application.py(664): launch_instance\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\site-packages\\ipykernel_launcher.py(16): <module>\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\runpy.py(85): _run_code\nC:\\Users\\KRPTN\\Anaconda3\\envs\\alphapose\\lib\\runpy.py(193): _run_module_as_main\n\n\nGraph we tried to export:\ngraph(%input : Float(1, 65, 13),\n      %gru.weight_ih_l0 : Float(1800, 13),\n      %gru.weight_hh_l0 : Float(1800, 600),\n      %gru.bias_ih_l0 : Float(1800),\n      %gru.bias_hh_l0 : Float(1800),\n      %fc.weight : Float(5, 600),\n      %fc.bias : Float(5)):\n  %7 : Long() = onnx::Constant[value={0}](), scope: RNN\n  %8 : Tensor = onnx::Shape(%input), scope: RNN\n  %9 : Long() = onnx::Gather[axis=0](%8, %7), scope: RNN\n  %10 : Long() = onnx::Constant[value={1}](), scope: RNN\n  %11 : Long() = onnx::Constant[value={600}](), scope: RNN\n  %12 : Tensor = onnx::Unsqueeze[axes=[0]](%10)\n  %13 : Tensor = onnx::Unsqueeze[axes=[0]](%9)\n  %14 : Tensor = onnx::Unsqueeze[axes=[0]](%11)\n  %15 : Tensor = onnx::Concat[axis=0](%12, %13, %14)\n  %16 : Float(1, 1, 600) = onnx::ConstantOfShape[value={0}](%15), scope: RNN\n  %17 : Float(1, 1, 600) = onnx::Cast[to=1](%16), scope: RNN\n  %18 : Long() = onnx::Constant[value={1}](), scope: RNN/GRU[gru]\n  %19 : Long() = onnx::Constant[value={1}](), scope: RNN/GRU[gru]\n  %20 : Double() = onnx::Constant[value={0}](), scope: RNN/GRU[gru]\n  %21 : Long() = onnx::Constant[value={0}](), scope: RNN/GRU[gru]\n  %22 : Long() = onnx::Constant[value={0}](), scope: RNN/GRU[gru]\n  %23 : Long() = onnx::Constant[value={1}](), scope: RNN/GRU[gru]\n  %24 : Float(1!, 65, 600), %25 : Float(1, 1, 600) = aten::gru(%input, %17, %gru.weight_ih_l0, %gru.weight_hh_l0, %gru.bias_ih_l0, %gru.bias_hh_l0, %18, %19, %20, %21, %22, %23), scope: RNN\n  %26 : Long() = onnx::Constant[value={-1}](), scope: RNN\n  %27 : Float(1, 600) = onnx::Gather[axis=1](%24, %26), scope: RNN/Dropout[do]\n  %28 : Float(1, 5) = onnx::Gemm[alpha=1, beta=1, transB=1](%27, %fc.weight, %fc.bias), scope: RNN/Dropout[do]\n  %output : Float(1, 5) = onnx::Sigmoid(%28), scope: RNN\n  return (%output)\n"
     ]
    }
   ],
   "source": [
    "#optional: export as ONNX model\n",
    "model.eval()\n",
    "batch_sizer = 1\n",
    "x = torch.randn(batch_sizer, 65, 13, requires_grad=True).to(device)\n",
    "\n",
    "torch_out = model(x)\n",
    "\n",
    "# Export the model\n",
    "torch.onnx.export(model,               # model being run\n",
    "                  x,                         # model input (or a tuple for multiple inputs)\n",
    "                  \"Genre__cls__81_3.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=10,          # the ONNX version to export the model to\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "predictions_one_hot = model.predict(inputs_test)\n",
    "print(targets_test.shape, predictions_one_hot.shape)\n",
    "# cm = confusion_matrix(targets_test, predictions_one_hot.argmax(axis=1))\n",
    "# print(cm)\n",
    "con_mat = tf.math.confusion_matrix(labels=targets_test, predictions=predictions_one_hot.argmax(axis=1)).numpy()\n",
    "con_mat_norm = np.around(con_mat.astype('float') / con_mat.sum(axis=1)[:, np.newaxis], decimals=2)\n",
    "\n",
    "con_mat_df = pd.DataFrame(con_mat_norm,\n",
    "                     index = outp_key, \n",
    "                     columns = outp_key)\n",
    "figure = plt.figure(figsize=(8, 8))\n",
    "sns.heatmap(con_mat_df, annot=True,cmap=plt.cm.Blues)\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal, sr = librosa.load(\"../raw_dataset/files/BIG ROOM/01 Agus Zack _ Devbanz - Workout (Extended M.mp3\") # len(signal) = 661794  # sr is 22050 by default "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signal.shape[0]\n",
    "mfcc = librosa.feature.mfcc(signal[0 : 22050*30],\n",
    "                                                   sr = 22050,\n",
    "                                                   n_fft = 4084,\n",
    "                                                   n_mfcc = 13,\n",
    "                                                   hop_length = 1024)\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib import cm\n",
    "\n",
    "# (rate,sig) = wav.read(\"file.wav\")\n",
    "mfcc_feat = mfcc\n",
    "\n",
    "ig, ax = plt.subplots()\n",
    "mfcc_data= np.swapaxes(mfcc_feat, 0 ,1)\n",
    "cax = ax.imshow(mfcc_data, interpolation='nearest', cmap=cm.coolwarm, origin='lower', aspect='auto')\n",
    "ax.set_title('MFCC')\n",
    "#Showing mfcc_data\n",
    "plt.show()\n",
    "#Showing mfcc_feat\n",
    "plt.plot(mfcc_feat)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfcc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
